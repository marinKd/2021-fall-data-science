{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEjPEOd93QJU",
    "outputId": "6d1c3bb9-7c51-40d4-f2a6-a2ff82ee37ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Layers for our neural networks\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "# A pretrained model for transfer learning\n",
    "from keras.models import Model\n",
    "from keras.applications import vgg19\n",
    "\n",
    "# Our normal python data science stack you've come to know and love\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIb__qFU3t1n"
   },
   "source": [
    "You're going to use a neural network to make predictions on the MNIST Fashion data set.  Check out the documentation here, make sure you check the size of the images and how many classes are in the data set https://keras.io/api/datasets/fashion_mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k1roY6I8iEe"
   },
   "outputs": [],
   "source": [
    "# switch runtime to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErpvW92D3lHy",
    "outputId": "1284f13c-9ea5-460e-94ef-82674d9ef090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "26435584/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the fashion mnist data set using tf.keras.datasets.fashion_mnist.load_data()\n",
    "tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rDlqLUNv34RV"
   },
   "outputs": [],
   "source": [
    "# divide the values by 255 and reshape \n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "y_train = y_train.reshape(-1)\n",
    "\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PTmgrqVS4BK1"
   },
   "outputs": [],
   "source": [
    "# build the architecture of your model using Sequential()\n",
    "model = tf.keras.models.Sequential()\n",
    "# you can use the same architecture we used in class, try to put your own spin on it, or copy another existing architecture\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(28,28, 1),filters=28,kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=28,kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=28,kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=28,kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# make sure you set the correct input shape and the correct parameters for the last dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O395g8-G4HJW"
   },
   "outputs": [],
   "source": [
    "# compile your model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjZrNiiq4Ja1",
    "outputId": "f4794552-7c9c-4f50-ecca-48e7042d312e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1688/1688 [==============================] - 46s 10ms/step - loss: 0.1493 - acc: 0.9523 - val_loss: 0.0616 - val_acc: 0.9830\n",
      "Epoch 2/12\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0515 - acc: 0.9844 - val_loss: 0.0424 - val_acc: 0.9870\n",
      "Epoch 3/12\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0404 - acc: 0.9879 - val_loss: 0.0308 - val_acc: 0.9907\n",
      "Epoch 4/12\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0295 - acc: 0.9914 - val_loss: 0.0490 - val_acc: 0.9867\n",
      "Epoch 5/12\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0270 - acc: 0.9922 - val_loss: 0.0296 - val_acc: 0.9928\n",
      "Epoch 6/12\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0226 - acc: 0.9930 - val_loss: 0.0488 - val_acc: 0.9898\n",
      "Epoch 7/12\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0201 - acc: 0.9943 - val_loss: 0.0289 - val_acc: 0.9918\n",
      "Epoch 8/12\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0166 - acc: 0.9952 - val_loss: 0.0374 - val_acc: 0.9915\n",
      "Epoch 9/12\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0158 - acc: 0.9951 - val_loss: 0.0486 - val_acc: 0.9893\n",
      "Epoch 10/12\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0150 - acc: 0.9958 - val_loss: 0.0469 - val_acc: 0.9890\n",
      "Epoch 11/12\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0146 - acc: 0.9958 - val_loss: 0.0331 - val_acc: 0.9912\n",
      "Epoch 12/12\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0130 - acc: 0.9963 - val_loss: 0.0419 - val_acc: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2a0126110>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit your model\n",
    "epochs = 12\n",
    "model.fit(x_train, y_train, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cf_vRXWf4mL2",
    "outputId": "6c4f27dc-cae1-417d-dc6b-6935519ef814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0324 - acc: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03237416222691536, 0.9927999973297119]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate your results\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vVQ48aK4nWF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Week9_Neural_Networks_Exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
